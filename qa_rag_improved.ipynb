{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be466394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All dependencies imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Simplified and optimized for better Greek text processing\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "print(\"All dependencies imported successfully!\")\n",
    "\n",
    "\n",
    "# Configuration\n",
    "LLM_MODEL = \"ilsp/meltemi-instruct\"\n",
    "ARTIFACTS_FILE = \"artefacts.json\"\n",
    "VECTOR_STORE_PATH = \"museum_faiss_langchain\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1ffbe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# STEP 1: Load and preprocess data\n",
    "def extract_field_text(field_data):\n",
    "    \"\"\"Extract text from multilingual field\"\"\"\n",
    "    if isinstance(field_data, dict):\n",
    "        return field_data.get('gr', '') or str(field_data.get(list(field_data.keys())[0] if field_data.keys() else '', ''))\n",
    "    elif isinstance(field_data, str):\n",
    "        return field_data\n",
    "    else:\n",
    "        return str(field_data) if field_data else ''\n",
    "\n",
    "def clean_html_text(text):\n",
    "    \"\"\"Clean HTML tags and normalize text\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    \n",
    "    # Decode HTML entities\n",
    "    text = text.replace('&lt;', '<').replace('&gt;', '>').replace('&amp;', '&')\n",
    "    text = text.replace('&nbsp;', ' ').replace('&quot;', '\"')\n",
    "    \n",
    "    # Normalize whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "def load_museum_data(artifacts_file):\n",
    "    \"\"\"Load museum data from JSON file with improved preprocessing\"\"\"\n",
    "    print(f\"Loading data from {artifacts_file}...\")\n",
    "    \n",
    "    with open(artifacts_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    processed = []\n",
    "    for item in data.get('data', []):\n",
    "        if not item.get('attributes'):\n",
    "            continue\n",
    "            \n",
    "        attrs = item['attributes']\n",
    "        \n",
    "        # Extract and clean text content\n",
    "        title = clean_html_text(extract_field_text(attrs.get('title', '')))\n",
    "        description = clean_html_text(extract_field_text(attrs.get('description', '')))\n",
    "        creator = clean_html_text(extract_field_text(attrs.get('creator', '')))\n",
    "        subtitle = clean_html_text(extract_field_text(attrs.get('subtitle', '')))\n",
    "        \n",
    "        # Skip items with no meaningful content\n",
    "        if not title and not description:\n",
    "            continue\n",
    "        \n",
    "        artifact = {\n",
    "            \"id\": item['id'],\n",
    "            \"code\": attrs.get('code', ''),\n",
    "            \"title\": title,\n",
    "            \"creator\": creator,\n",
    "            \"subtitle\": subtitle,\n",
    "            \"description\": description,         \n",
    "            \"room\": attrs.get('mapRoom', ''),\n",
    "            \"category\": \"MUSEUM_ARTIFACT\"\n",
    "        }\n",
    "        processed.append(artifact)\n",
    "    \n",
    "    print(f\"Loaded {len(processed)} artifacts\")\n",
    "    return processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec1bc10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# STEP 2: Create Documents with better chunking\n",
    "def create_documents(artifacts):\n",
    "    \"\"\"Create LangChain documents from artifacts with improved chunking\"\"\"\n",
    "    print(\"Creating LangChain documents...\")\n",
    "    \n",
    "    # Greek-optimized text splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=800,  # Larger chunks for better context\n",
    "        chunk_overlap=100,  # Good overlap for context preservation\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \"! \", \"? \", \"; \", \", \", \" \", \"\"],\n",
    "        keep_separator=True\n",
    "    )\n",
    "    \n",
    "    all_documents = []\n",
    "    \n",
    "    for artifact in tqdm(artifacts, desc=\"Processing artifacts\"):\n",
    "        # Combine artifact information in a structured way\n",
    "        full_text = f\"\"\"Title: {artifact['title']}\n",
    "Creator: {artifact['creator']}\n",
    "Subtitle: {artifact['subtitle']}\n",
    "Code: {artifact['code']}\n",
    "Room: {artifact['room']}\n",
    "Description: {artifact['description']}\n",
    "Category: {artifact['category']}\"\"\"\n",
    "        \n",
    "        # Split text into chunks\n",
    "        chunks = text_splitter.split_text(full_text.strip())\n",
    "        \n",
    "        # Create Document objects with meaningful chunks only\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            if len(chunk.strip()) > 50:  # Filter very short chunks\n",
    "                doc = Document(\n",
    "                    page_content=chunk,\n",
    "                    metadata={\n",
    "                        'artifact_id': artifact['id'],\n",
    "                        'title': artifact['title'],\n",
    "                        'creator': artifact['creator'],\n",
    "                        'room': artifact['room'],\n",
    "                        'chunk_id': i,\n",
    "                        'source': 'museum_artifact'\n",
    "                    }\n",
    "                )\n",
    "                all_documents.append(doc)\n",
    "    \n",
    "    print(f\"Created {len(all_documents)} document chunks\")\n",
    "    return all_documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f532f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# STEP 3: Setup improved embeddings\n",
    "def setup_embeddings():\n",
    "    \"\"\"Setup embedding model optimized for Greek text\"\"\"\n",
    "    print(\"Loading embedding model...\")\n",
    "    \n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\",\n",
    "        model_kwargs={'device': 'cpu'},\n",
    "        encode_kwargs={'normalize_embeddings': True}\n",
    "    )\n",
    "    \n",
    "    print(\"Embedding model loaded successfully!\")\n",
    "    return embeddings\n",
    "\n",
    "# STEP 4: Create vector store with better retrieval\n",
    "def create_vector_store(documents, embeddings):\n",
    "    \"\"\"Create FAISS vector store from documents with improved settings\"\"\"\n",
    "    print(\"Creating vector store...\")\n",
    "    \n",
    "    if not documents:\n",
    "        print(\"No documents found!\")\n",
    "        return None, None\n",
    "    \n",
    "    # Create vector store with cosine similarity\n",
    "    vectorstore = FAISS.from_documents(\n",
    "        documents=documents,\n",
    "        embedding=embeddings\n",
    "    )\n",
    "    \n",
    "    # Create retriever with better parameters\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=\"similarity_score_threshold\",\n",
    "        search_kwargs={\n",
    "            \"k\": 5,  # Retrieve top 5 chunks\n",
    "            \"score_threshold\": 0.3  # Minimum relevance threshold\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(\"Vector store created successfully!\")\n",
    "    return vectorstore, retriever\n",
    "\n",
    "def save_vector_store(vectorstore, path):\n",
    "    \"\"\"Save vector store to disk\"\"\"\n",
    "    if vectorstore:\n",
    "        vectorstore.save_local(path)\n",
    "        print(f\"Vector store saved to {path}\")\n",
    "\n",
    "def load_vector_store(path, embeddings):\n",
    "    \"\"\"Load vector store from disk\"\"\"\n",
    "    vectorstore = FAISS.load_local(path, embeddings, allow_dangerous_deserialization=True)\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=\"similarity_score_threshold\",\n",
    "        search_kwargs={\"k\": 5, \"score_threshold\": 0.3}\n",
    "    )\n",
    "    print(f\"Vector store loaded from {path}\")\n",
    "    return vectorstore, retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abe2ff3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5: Setup LLM\n",
    "def setup_llm(llm_model):\n",
    "    \"\"\"Setup Ollama LLM with optimized parameters\"\"\"\n",
    "    print(f\"Loading LLM: {llm_model}...\")\n",
    "    \n",
    "    llm = OllamaLLM(\n",
    "        model=llm_model, \n",
    "        temperature=0.1,\n",
    "        num_predict=512,  # Reasonable response length\n",
    "        num_thread=4\n",
    "    )\n",
    "    \n",
    "    print(\"LLM loaded successfully!\")\n",
    "    return llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac799d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 6: Create RAG chain\n",
    "def create_rag_chain(llm, retriever):\n",
    "    \"\"\"Create RAG chain with Greek language support and better prompting\"\"\"\n",
    "    print(\"Setting up Greek-aware RAG chain...\")\n",
    "\n",
    "    template = \"\"\"Είσαι ένας ειδικός βοηθός μουσείου στη Βιβλιοθήκη Ωνάση που απαντά σε ερωτήσεις για αντικείμενα και έργα τέχνης.\n",
    "\n",
    "Χρησιμοποίησε τις παρακάτω πληροφορίες για να απαντήσεις στην ερώτηση:\n",
    "{context}\n",
    "\n",
    "Ερώτηση: {question}\n",
    "\n",
    "Οδηγίες:\n",
    "- Εάν η ερώτηση είναι στα ελληνικά, απάντησε στα ελληνικά\n",
    "- Εάν η ερώτηση είναι στα αγγλικά, απάντησε στα αγγλικά\n",
    "- Χρησιμοποίησε τις πληροφορίες από το πλαίσιο για να δώσεις μια λεπτομερή απάντηση\n",
    "- Παρέχε εκπαιδευτικές και ενδιαφέρουσες πληροφορίες\n",
    "- Εάν το πλαίσιο δεν περιέχει σχετικές πληροφορίες, πες το στην κατάλληλη γλώσσα\n",
    "\n",
    "Απάντηση:\"\"\"\n",
    "    \n",
    "    # Create prompt\n",
    "    prompt = PromptTemplate(\n",
    "        template=template,\n",
    "        input_variables=[\"question\", \"context\"]\n",
    "    )\n",
    "    \n",
    "    # Create QA chain\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "        chain_type_kwargs={\"prompt\": prompt},\n",
    "        return_source_documents=True\n",
    "    )\n",
    "    \n",
    "    print(\"RAG chain setup complete!\")\n",
    "    return qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88ff1030",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# STEP 7: Query functions with improved processing\n",
    "def preprocess_question(question):\n",
    "    \"\"\"Preprocess question for better retrieval\"\"\"\n",
    "    \n",
    "    question = question.strip()\n",
    "    \n",
    "    # Expand common Greek terms with synonyms for better retrieval\n",
    "    expansions = {\n",
    "        'Ωνάσης': 'Ωνάσης Αριστοτέλης Onassis',\n",
    "        'Κάλλας': 'Κάλλας Μαρία Callas',\n",
    "        'μουσείο': 'μουσείο έκθεση συλλογή',\n",
    "        'αντικείμενο': 'αντικείμενο έργο artifact',\n",
    "        'ζωγραφικός': 'ζωγραφικός πίνακας painting',\n",
    "        'γλυπτό': 'γλυπτό sculpture άγαλμα',\n",
    "        'καθρέφτης': 'καθρέφτης mirror καθρέπτης'\n",
    "    }\n",
    "    \n",
    "    processed = question\n",
    "    for key, value in expansions.items():\n",
    "        if key in processed:\n",
    "            processed = processed.replace(key, value)\n",
    "    \n",
    "    return processed\n",
    "\n",
    "def query_with_rag(qa_chain, question):\n",
    "    \"\"\"Query using RAG with improved error handling\"\"\"\n",
    "    if not qa_chain:\n",
    "        return \"QA chain not setup!\"\n",
    "    \n",
    "    try:\n",
    "        # Preprocess question\n",
    "        processed_question = preprocess_question(question)\n",
    "        \n",
    "        # Get answer\n",
    "        result = qa_chain.invoke({\"query\": processed_question})\n",
    "        answer = result[\"result\"]\n",
    "        source_docs = result[\"source_documents\"]\n",
    "        \n",
    "        # Clean answer from template artifacts\n",
    "        answer = clean_answer(answer)\n",
    "        \n",
    "        return {\n",
    "            \"answer\": answer,\n",
    "            \"source_documents\": source_docs,\n",
    "            \"question\": question,\n",
    "            \"processed_question\": processed_question\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error during query: {e}\")\n",
    "        return {\n",
    "            \"answer\": f\"Συγγνώμη, προέκυψε σφάλμα: {str(e)}\",\n",
    "            \"source_documents\": [],\n",
    "            \"question\": question,\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "\n",
    "def clean_answer(answer):\n",
    "    \"\"\"Clean the answer from template artifacts\"\"\"\n",
    "    if not answer or len(answer.strip()) < 5:\n",
    "        return \"Δεν βρέθηκαν επαρκείς πληροφορίες για την ερώτηση αυτή.\"\n",
    "    \n",
    "    answer = answer.strip()\n",
    "    \n",
    "    # Remove common template artifacts\n",
    "    unwanted_prefixes = [\n",
    "        \"Είσαι ένας ειδικός βοηθός\",\n",
    "        \"Χρησιμοποίησε τις παρακάτω\",\n",
    "        \"Πλαίσιο:\",\n",
    "        \"Ερώτηση:\",\n",
    "        \"Απάντηση:\",\n",
    "        \"Οδηγίες:\"\n",
    "    ]\n",
    "    \n",
    "    for prefix in unwanted_prefixes:\n",
    "        if answer.startswith(prefix):\n",
    "            answer = answer[len(prefix):].strip()\n",
    "    \n",
    "    # Ensure proper capitalization\n",
    "    if answer and not answer[0].isupper():\n",
    "        answer = answer[0].upper() + answer[1:]\n",
    "    \n",
    "    # Add period if missing\n",
    "    if answer and not answer.endswith(('.', '!', '?')):\n",
    "        answer += '.'\n",
    "    \n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8aedcf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# STEP 8: Main workflow function\n",
    "def create_greek_qa_system(artifacts_file):\n",
    "    \"\"\"Create the complete Greek QA system\"\"\"\n",
    "    \n",
    "    print(\"Initializing Greek QA RAG System...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    print(\"Step 1: Loading and preprocessing documents...\")\n",
    "    artifacts = load_museum_data(artifacts_file)\n",
    "    \n",
    "    if not artifacts:\n",
    "        print(\"No artifacts loaded. Please check your JSON file.\")\n",
    "        return None\n",
    "    \n",
    "    # Create documents\n",
    "    print(\"Step 2: Creating document chunks...\")\n",
    "    documents = create_documents(artifacts)\n",
    "    \n",
    "    # Setup embeddings\n",
    "    print(\"Step 3: Setting up embeddings...\")\n",
    "    embeddings = setup_embeddings()\n",
    "    \n",
    "    # Create vector store\n",
    "    print(\"Step 4: Building vector database...\")\n",
    "    vectorstore, retriever = create_vector_store(documents, embeddings)\n",
    "    save_vector_store(vectorstore, VECTOR_STORE_PATH)\n",
    "    \n",
    "    # Setup LLM\n",
    "    print(\"Step 5: Initializing LLM...\")\n",
    "    llm = setup_llm(LLM_MODEL)\n",
    "    \n",
    "    # Create QA chain\n",
    "    print(\"Step 6: Building QA chain...\")\n",
    "    qa_chain = create_rag_chain(llm, retriever)\n",
    "    \n",
    "    print(\"Greek QA RAG System ready!\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return qa_chain, vectorstore, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96d0b514",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# STEP 9: Test function\n",
    "def test_system(qa_chain):\n",
    "    \"\"\"Test the system with Greek questions\"\"\"\n",
    "    \n",
    "    test_questions = [\n",
    "        \"Δώσε μου πληροφορίες για τα γλυπτά του μουσείου\",\n",
    "        \"Ποιοι είναι οι διάσημοι ζωγράφοι που έχουν έργα στη συλλογή\",\n",
    "        \"Δώσε μου πληροφορίες για τους πίνακες του μουσείου\",\n",
    "        \"Δώσε μου πληροφορίες για τον Ωνάση\",\n",
    "        \"Δώσε μου πληροφορίες για τα εκθέματα που αφορούν τον Ωνάση\"\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    print(\"Testing RAG Pipeline:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i, question in enumerate(test_questions):\n",
    "        print(f\"\\nQUESTION {i+1}: {question}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        try:\n",
    "            # RAG query\n",
    "            rag_result = query_with_rag(qa_chain, question)\n",
    "            print(f\"RAG Answer: {rag_result['answer']}\")\n",
    "            \n",
    "            print(f\"\\nSources ({len(rag_result['source_documents'])}):\") \n",
    "            for j, doc in enumerate(rag_result['source_documents'][:3]):\n",
    "                print(f\"  {j+1}. {doc.metadata.get('title', 'Unknown')}\")\n",
    "                print(f\"     Creator: {doc.metadata.get('creator', 'Unknown')}\")\n",
    "                print(f\"     Room: {doc.metadata.get('room', 'Unknown')}\")\n",
    "                print(f\"     Content: {doc.page_content[:100]}...\")\n",
    "            \n",
    "            results.append(rag_result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "    \n",
    "    # Print summary\n",
    "    successful = sum(1 for r in results if 'error' not in r)\n",
    "    print(f\"\\nTest Results: {successful}/{len(test_questions)} successful\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac0ccde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Greek QA RAG System...\n",
      "============================================================\n",
      "Step 1: Loading and preprocessing documents...\n",
      "Loading data from artefacts.json...\n",
      "Loaded 86 artifacts\n",
      "Step 2: Creating document chunks...\n",
      "Creating LangChain documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing artifacts: 100%|██████████| 86/86 [00:00<00:00, 7569.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 156 document chunks\n",
      "Step 3: Setting up embeddings...\n",
      "Loading embedding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding model loaded successfully!\n",
      "Step 4: Building vector database...\n",
      "Creating vector store...\n",
      "Vector store created successfully!\n",
      "Vector store saved to museum_faiss_langchain\n",
      "Step 5: Initializing LLM...\n",
      "Loading LLM: ilsp/meltemi-instruct...\n",
      "LLM loaded successfully!\n",
      "Step 6: Building QA chain...\n",
      "Setting up Greek-aware RAG chain...\n",
      "RAG chain setup complete!\n",
      "Greek QA RAG System ready!\n",
      "============================================================\n",
      "Testing RAG Pipeline:\n",
      "============================================================\n",
      "\n",
      "QUESTION 1: Δώσε μου πληροφορίες για τα γλυπτά του μουσείου\n",
      "------------------------------------------------------------\n",
      "RAG Answer: Δώσε μου πληροφορίες για τα γλυπτά του μουσείου έκθεση συλλογήυ\n",
      "\n",
      "Γεια σας! Θα χαρούμε να σας δώσω πληροφορίες σχετικά με τη συλλογή γλυπτών της Βιβλιοθήκης Ωνάσση.\n",
      "\n",
      "Η Βιβλιοθήκη Ωνάσση διαθέτει μια εντυπωσιακή συλλογή γλυπτών, η οποία περιλαμβάνει έργα από μερικούς από τους πιο σημαντικούς Έλληνες και διεθνείς καλλιτέχνες. Ακολουθούν μερικά παραδείγματα:\n",
      "\n",
      "1. \"Altars 3\" του Silvina Der Meguerditchian: Αυτό το έργο τέχνης δημιουργήθηκε το 2018 και είναι κατασκευασμένο από βελούδο, μεταλλικά αντικείμενα και χρυσές χάντρες. Είναι ένα εντυπωσιακό κομμάτι που σίγουρα θα τραβήξει την προσοχή σας.\n",
      "\n",
      "2. «Γητεύτρα Φιδιών» του Θεόδωρου Ράλλη: Αυτός ο πίνακας ζωγραφικής δημιουργήθηκε το 1882 και απεικονίζει μια γυναίκα να κρατά λουλούδια σε έναν κήπο. Είναι ένα όμορφο έργο τέχνης που αναδεικνύει τις καλλιτεχνικές δεξιότητες του Ράλλη.\n",
      "\n",
      "3. \"Ζεύγος μαρμάρινων κιόκων\": Αυτό είναι ένα αρχαίο γλυπτό από την Ελλάδα, που χρονολογείται γύρω στο 2810 π.Χ. Είναι κατασκευασμένο από μάρμαρο και απεικονίζει δύο ανθρώπους να αγκαλιάζονται σε έναν κήπο. Είναι μια όμορφη αναπαράσταση της αγάπης και της ομορφιάς στην αρχαία ελληνική τέχνη.\n",
      "\n",
      "4. \"Το κτίριο της Ωνασείου Βιβλιοθήκης\": Αυτό είναι ένα σύγχρονο έργο τέχνης που δημιουργήθηκε το 1997, σχεδιασμένο από τον αρχιτέκτονα Bernard Tschumi. Το κτίριο βρίσκεται στο κέντρο της Αθήνας και φιλοξενεί τη συλλογή γλυπτών της Βιβλιοθήκης Ωνάσση. Είναι μια εντυπωσιακή κατασκευή που αναδεικνύει την ομορφιά και την κομψότητα του σύγχρονου σχεδιασμού.\n",
      "\n",
      "Η Βιβλιοθήκη Ωνάσση διαθέτει επίσης πολλά άλλα έργα τέχνης, συμπεριλαμβανομένων έργων από μερικούς από τους πιο σημαντικούς Έλληνες καλλιτέχνες όπως ο Γιάννης Μόραλης, ο Νίκος Εγγονόπουλος και η Ελένη Καραγιάννη. Η συλλογή περιλαμβάνει επίσης έργα από διεθνείς καλλιτέχνες όπως ο Michelangelo, ο Renoir και ο Picasso.\n",
      "\n",
      "Εάν ενδιαφέρεστε να επισκεφτείτε τη Βιβλιοθήκη Ωνάσση για να δείτε τα γλυπτά της συλλογής αυτοπροσώπως, μπορείτε να επικοινωνήσετε μαζί τους μέσω του ιστότοπού τους ή τηλεφωνώντας στο 2103617089. Θα χαρούν να σας ξεναγήσουν στη συλλογή και να απαντήσουν σε οποιεσδήποτε ερωτήσεις μπορεί να έχετε.\n",
      "\n",
      "Ελπίζω αυτές οι πληροφορίες να είναι χρήσιμες! Ενημερώστε με αν έχετε περισσότερες ερωτήσεις.\n",
      "\n",
      "Sources (5):\n",
      "  1. Altars 3\n",
      "     Creator: Silvina Der Meguerditchian (1967- )\n",
      "     Room: None\n",
      "     Content: Title: Altars 3\n",
      "Creator: Silvina Der Meguerditchian (1967- )\n",
      "Subtitle: 2018, βελούδο, μεταλλικά αντι...\n",
      "  2. Αυγή και Εσπέρα\n",
      "     Creator: Γεώργιος Βρούτος (1843-1909)\n",
      "     Room: Library\n",
      "     Content: . Στην προκειμένη περίπτωση, το πρότυπο για την Αυγή και την Εσπέρα πρέπει να ήταν τα γλυπτά του Mic...\n",
      "  3. Γητεύτρα Φιδιών\n",
      "     Creator: Θεόδωρος Ράλλης (1852-1909)\n",
      "     Room: None\n",
      "     Content: Title: Γητεύτρα Φιδιών\n",
      "Creator: Θεόδωρος Ράλλης (1852-1909)\n",
      "Subtitle: 1882, λάδι σε πανί, 90 χ 116,5...\n",
      "\n",
      "============================================================\n",
      "\n",
      "QUESTION 2: Ποιοι είναι οι διάσημοι ζωγράφοι που έχουν έργα στη συλλογή\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# USAGE EXAMPLE\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize the system\n",
    "    qa_chain, vectorstore, embeddings = create_greek_qa_system(ARTIFACTS_FILE)\n",
    "    \n",
    "    if qa_chain:\n",
    "        # Test the system\n",
    "        test_results = test_system(qa_chain)\n",
    "        \n",
    "        # Start interactive mode (uncomment to use)\n",
    "        # interactive_qa(qa_chain)\n",
    "        \n",
    "        print(\"\\nGreek QA RAG System Complete!\")\n",
    "        #print(\"Use interactive_qa(qa_chain) for interactive questions.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
